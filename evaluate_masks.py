import os
import cv2
import numpy as np

# =====================================================
# ðŸ”§ PATH CONFIGURATION (EDIT ONLY IF PATH CHANGES)
# =====================================================

# Ground Truth cloth masks (from dataset)
GT_MASK_DIR = r"C:\Users\ayush\Downloads\archive\Virtual tryon data\train\cloth-mask"

# Predicted masks generated by your model
PRED_MASK_DIR = r"C:\Users\ayush\Desktop\Internship\Imp Files\virtual-try-on-dataset\clothes-segmentation\outputs"

# =====================================================
# ðŸ“Š METRIC FUNCTIONS
# =====================================================

def iou_score(pred, gt):
    intersection = np.logical_and(pred, gt).sum()
    union = np.logical_or(pred, gt).sum()
    return intersection / (union + 1e-6)

def dice_score(pred, gt):
    intersection = np.logical_and(pred, gt).sum()
    return 2 * intersection / (pred.sum() + gt.sum() + 1e-6)

# =====================================================
# ðŸš€ EVALUATION LOOP
# =====================================================

iou_scores = []
dice_scores = []

evaluated = 0
missing_gt = 0
skipped = 0

# Build GT filename map (base_name â†’ full filename)
gt_files = {
    os.path.splitext(f)[0]: f
    for f in os.listdir(GT_MASK_DIR)
}

for pred_file in os.listdir(PRED_MASK_DIR):
    pred_base = os.path.splitext(pred_file)[0]

    if pred_base not in gt_files:
        missing_gt += 1
        continue

    pred_path = os.path.join(PRED_MASK_DIR, pred_file)
    gt_path = os.path.join(GT_MASK_DIR, gt_files[pred_base])

    pred = cv2.imread(pred_path, cv2.IMREAD_GRAYSCALE)
    gt = cv2.imread(gt_path, cv2.IMREAD_GRAYSCALE)

    if pred is None or gt is None:
        skipped += 1
        continue

    # ðŸ”§ IMPORTANT: Resize GT to predicted size
    gt = cv2.resize(
        gt,
        (pred.shape[1], pred.shape[0]),
        interpolation=cv2.INTER_NEAREST
    )

    # Convert to binary masks
    pred = pred > 127
    gt = gt > 127

    iou_scores.append(iou_score(pred, gt))
    dice_scores.append(dice_score(pred, gt))
    evaluated += 1

# =====================================================
# ðŸ“ˆ FINAL RESULTS
# =====================================================

print("===================================")
print(f"Evaluated samples : {evaluated}")
print(f"Missing GT masks  : {missing_gt}")
print(f"Skipped samples   : {skipped}")

if evaluated > 0:
    print(f"Mean IoU Score    : {np.mean(iou_scores):.4f}")
    print(f"Mean Dice Score   : {np.mean(dice_scores):.4f}")
else:
    print("Mean IoU Score    : N/A")
    print("Mean Dice Score   : N/A")

print("===================================")
